-- April Snippets: Testing, Debugging & Performance
INSERT INTO snippets (month, day, title, code, explanation, language_id, category_id) VALUES
(4, 1, 'April Fools Code', '#include <stdio.h>\n#define true false\n#define false true\nint main() {\n    if (true) {\n        printf("This is false!\\n");\n    }\n    if (false) {\n        printf("This is true!\\n");\n    }\n    // Happy April Fools!\n    return 0;\n}', 'April Fools! Macro definitions can redefine keywords. Never do this in real code. Demonstrates preprocessor power and dangers.', 2, 10),
(4, 2, 'Unit Testing Basics', '#include <assert.h>\nvoid test_addition() {\n    assert(add(2, 2) == 4);\n    assert(add(-1, 1) == 0);\n    assert(add(0, 0) == 0);\n}\nvoid test_division() {\n    assert(divide(10, 2) == 5);\n    assert(divide(7, 2) == 3);  // Integer division\n}\nint main() {\n    test_addition();\n    test_division();\n    printf("All tests passed!\\n");\n}', 'Unit tests verify individual functions. assert() checks conditions. Test edge cases, normal cases, error cases. Foundation of TDD.', 2, 10),
(4, 3, 'Python pytest', 'import pytest\n\ndef test_string_methods():\n    assert "hello".upper() == "HELLO"\n    assert "HELLO".lower() == "hello"\n    \n@pytest.mark.parametrize("input,expected", [\n    (2, 4),\n    (3, 9),\n    (4, 16),\n])\ndef test_square(input, expected):\n    assert input ** 2 == expected\n\ndef test_exception():\n    with pytest.raises(ZeroDivisionError):\n        1 / 0', 'pytest simplifies testing. Parametrize runs multiple inputs. Fixtures share setup. Mark categorizes tests. Better than unittest.', 1, 10),
(4, 4, 'GDB Debugging', '# Compile with debug symbols\ngcc -g program.c -o program\n\n# GDB commands:\n(gdb) break main          # Set breakpoint\n(gdb) run                 # Start program\n(gdb) next                # Step over\n(gdb) step                # Step into\n(gdb) print variable      # Show value\n(gdb) backtrace          # Show call stack\n(gdb) watch variable     # Break on change\n(gdb) continue           # Resume execution', 'GDB debugs C/C++ programs. -g flag includes debug symbols. Breakpoints pause execution. Inspect variables, stack, memory. Essential debugging tool.', 2, 10),
(4, 5, 'Valgrind Memory Check', '// Memory leak example\nint main() {\n    int* arr = malloc(10 * sizeof(int));\n    // Missing free(arr);\n    return 0;\n}\n\n// Run: valgrind --leak-check=full ./program\n// Output:\n// ==1234== 40 bytes in 1 blocks definitely lost\n// ==1234== at 0x4C2AB80: malloc\n// ==1234== by 0x40053E: main', 'Valgrind detects memory leaks, invalid access. --leak-check=full shows details. Catches use-after-free, buffer overflows. No recompilation needed.', 2, 10),
(4, 6, 'JavaScript Console Debug', 'console.log("Basic output");\nconsole.error("Error message");\nconsole.warn("Warning");\nconsole.table([{a:1,b:2},{a:3,b:4}]);\nconsole.time("Timer");\n// Code to measure\nconsole.timeEnd("Timer");\nconsole.group("Group");\nconsole.log("Nested");\nconsole.groupEnd();\nconsole.trace();  // Stack trace\nconsole.assert(false, "Assertion failed");', 'Console methods aid debugging. table() formats data. time/timeEnd measure performance. group organizes output. trace shows call stack.', 5, 10),
(4, 7, 'Performance Profiling', '#include <time.h>\nclock_t start = clock();\n// Code to profile\nfor (int i = 0; i < 1000000; i++) {\n    // Work\n}\nclock_t end = clock();\ndouble cpu_time = ((double)(end - start)) / CLOCKS_PER_SEC;\nprintf("Execution time: %.6f seconds\\n", cpu_time);\n\n// Compile with: gcc -pg for gprof profiling\n// Run: ./program && gprof program', 'Measure execution time with clock(). gprof analyzes function calls. Identifies bottlenecks. Optimize hot paths first.', 2, 10),
(4, 8, 'Mock Objects Testing', 'class MockDatabase:\n    def __init__(self):\n        self.calls = []\n    \n    def query(self, sql):\n        self.calls.append(sql)\n        return [{"id": 1, "name": "Test"}]\n    \n    def insert(self, table, data):\n        self.calls.append((table, data))\n        return True\n\ndef test_user_service():\n    mock_db = MockDatabase()\n    service = UserService(mock_db)\n    service.get_user(1)\n    assert "SELECT" in mock_db.calls[0]', 'Mocks simulate dependencies. Test in isolation. Verify interactions. No real database needed. Faster, more reliable tests.', 1, 10),
(4, 9, 'C++ Google Test', '#include <gtest/gtest.h>\n\nTEST(MathTest, Addition) {\n    EXPECT_EQ(2 + 2, 4);\n    EXPECT_NE(2 + 2, 5);\n}\n\nTEST(StringTest, Substring) {\n    std::string str = "Hello World";\n    EXPECT_TRUE(str.find("World") != std::string::npos);\n    EXPECT_FALSE(str.empty());\n}\n\nint main(int argc, char** argv) {\n    ::testing::InitGoogleTest(&argc, argv);\n    return RUN_ALL_TESTS();\n}', 'Google Test framework for C++. EXPECT continues on failure, ASSERT stops. TEST defines test cases. Automated test discovery.', 3, 10),
(4, 10, 'Code Coverage', '# Generate coverage data\ngcc --coverage program.c -o program\n./program\ngcov program.c\n\n# Python coverage\npip install coverage\ncoverage run -m pytest\ncoverage report\ncoverage html\n\n# JavaScript with Jest\njest --coverage\n# Aim for 80%+ coverage\n# 100% is often impractical', 'Coverage measures tested code percentage. Identifies untested paths. gcov for C/C++, coverage.py for Python. Not quality guarantee.', 2, 10),
(4, 11, 'Sanitizers', '// Compile with sanitizers\n// gcc -fsanitize=address    # AddressSanitizer\n// gcc -fsanitize=undefined  # UBSan\n// gcc -fsanitize=thread     # ThreadSanitizer\n\nint main() {\n    int arr[10];\n    arr[10] = 42;  // Buffer overflow, caught by ASan\n    \n    int* p = NULL;\n    *p = 42;  // Null deref, caught by ASan\n    \n    int x;\n    if (x) {}  // Uninitialized, caught by MSan\n}', 'Sanitizers detect runtime errors. ASan: memory errors. UBSan: undefined behavior. TSan: data races. Small overhead, huge benefit.', 2, 10),
(4, 12, 'Benchmark Code', '#include <benchmark/benchmark.h>\n\nstatic void BM_StringCreation(benchmark::State& state) {\n    for (auto _ : state) {\n        std::string empty_string;\n    }\n}\nBENCHMARK(BM_StringCreation);\n\nstatic void BM_StringCopy(benchmark::State& state) {\n    std::string x = "hello";\n    for (auto _ : state) {\n        std::string copy(x);\n    }\n}\nBENCHMARK(BM_StringCopy);', 'Google Benchmark measures performance. Statistical analysis, outlier detection. Warm-up iterations. Prevents optimization. Reliable measurements.', 3, 10),
(4, 13, 'Python Debugging', 'import pdb\n\ndef buggy_function(x, y):\n    result = x * y\n    pdb.set_trace()  # Breakpoint\n    result += 10\n    return result\n\n# Interactive debugger commands:\n# n - next line\n# s - step into\n# c - continue\n# l - list code\n# p variable - print\n# pp - pretty print\n# h - help', 'pdb is Python debugger. set_trace() creates breakpoint. Interactive exploration. Inspect variables, step through code. Essential debugging tool.', 1, 10),
(4, 14, 'Memory Leak Detection', 'class LeakDetector {\n    static std::unordered_map<void*, size_t> allocations;\npublic:\n    static void* allocate(size_t size) {\n        void* ptr = malloc(size);\n        allocations[ptr] = size;\n        return ptr;\n    }\n    static void deallocate(void* ptr) {\n        allocations.erase(ptr);\n        free(ptr);\n    }\n    static void report() {\n        for (auto& [ptr, size] : allocations)\n            printf("Leak: %zu bytes at %p\\n", size, ptr);\n    }\n};', 'Custom leak detector tracks allocations. Override new/delete operators. Report unreleased memory. Simpler than Valgrind for basic needs.', 3, 10),
(4, 15, 'Integration Testing', 'def test_api_integration():\n    # Setup test database\n    with test_database():\n        # Create test data\n        user = create_test_user()\n        \n        # Test API endpoint\n        response = client.post("/login", {\n            "username": user.username,\n            "password": "testpass"\n        })\n        \n        assert response.status_code == 200\n        assert "token" in response.json()\n        \n        # Test authenticated request\n        token = response.json()["token"]\n        auth_response = client.get("/profile",\n            headers={"Authorization": f"Bearer {token}"})', 'Integration tests verify component interaction. Test real workflows. Database, API, authentication. Slower but catch integration bugs.', 1, 10),
(4, 16, 'Static Analysis', '// Tools for static analysis:\n// C/C++: clang-tidy, cppcheck, PVS-Studio\n// Python: pylint, mypy, flake8\n// JavaScript: ESLint, JSHint\n\n// Example cppcheck warnings:\n// [error] Null pointer dereference\n// [warning] Unused variable ''x''\n// [style] Variable can be const\n\n// Run: cppcheck --enable=all program.cpp\n// clang-tidy program.cpp -- -std=c++17', 'Static analysis finds bugs without running code. Catches common mistakes. Type errors, null derefs, resource leaks. Part of CI/CD pipeline.', 3, 10),
(4, 17, 'Fuzzing', '#include <stdint.h>\n#include <stddef.h>\n\nextern "C" int LLVMFuzzerTestOneInput(\n    const uint8_t* data, size_t size) {\n    if (size < 4) return 0;\n    \n    // Parse input as your format\n    if (data[0] == ''F'' && data[1] == ''U'' &&\n        data[2] == ''Z'' && data[3] == ''Z'') {\n        // Process the data\n        process_input(data + 4, size - 4);\n    }\n    return 0;\n}\n// Compile: clang++ -fsanitize=fuzzer,address', 'Fuzzing finds bugs with random input. LibFuzzer generates test cases. Coverage-guided evolution. Finds crashes, hangs, memory errors.', 3, 10),
(4, 18, 'Load Testing', 'import locust\nfrom locust import HttpUser, task, between\n\nclass WebsiteUser(HttpUser):\n    wait_time = between(1, 3)\n    \n    @task(3)\n    def view_products(self):\n        self.client.get("/products")\n    \n    @task(1)\n    def view_product(self):\n        product_id = random.randint(1, 100)\n        self.client.get(f"/products/{product_id}")\n    \n    @task(1)\n    def add_to_cart(self):\n        self.client.post("/cart", json={"product_id": 1})', 'Load testing simulates users. Locust creates distributed load. Find breaking points. Monitor response times, error rates. Plan capacity.', 1, 10),
(4, 19, 'Assertion Macros', '#define ASSERT(cond) \\\n    do { \\\n        if (!(cond)) { \\\n            fprintf(stderr, "Assertion failed: %s\\n" \\\n                    "File: %s, Line: %d\\n", \\\n                    #cond, __FILE__, __LINE__); \\\n            abort(); \\\n        } \\\n    } while(0)\n\n#ifdef DEBUG\n    #define DEBUG_ASSERT(cond) ASSERT(cond)\n#else\n    #define DEBUG_ASSERT(cond) ((void)0)\n#endif', 'Custom assertions with context. Macro shows file, line. DEBUG_ASSERT removed in release. do-while prevents if-else issues.', 2, 10),
(4, 20, 'Test Fixtures', 'class DatabaseTest : public ::testing::Test {\nprotected:\n    Database* db;\n    \n    void SetUp() override {\n        db = new Database(":memory:");\n        db->execute("CREATE TABLE users (id, name)");\n        db->execute("INSERT INTO users VALUES (1, ''Alice'')");\n    }\n    \n    void TearDown() override {\n        delete db;\n    }\n};\n\nTEST_F(DatabaseTest, QueryUser) {\n    auto result = db->query("SELECT * FROM users");\n    ASSERT_EQ(result.size(), 1);\n}', 'Fixtures provide test setup/teardown. Consistent test environment. Avoid test interdependence. Fresh state each test. Reduces duplication.', 3, 10),
(4, 21, 'Error Injection', 'class FaultInjector {\n    static bool should_fail;\n    static int fail_count;\npublic:\n    static void* malloc_wrapper(size_t size) {\n        if (should_fail && --fail_count <= 0) {\n            errno = ENOMEM;\n            return nullptr;\n        }\n        return malloc(size);\n    }\n    static void inject_failure(int after_n_calls) {\n        should_fail = true;\n        fail_count = after_n_calls;\n    }\n};\n#define malloc(size) FaultInjector::malloc_wrapper(size)', 'Error injection tests failure handling. Simulate out-of-memory, network errors. Verify graceful degradation. Chaos engineering principle.', 3, 10),
(4, 22, 'Continuous Integration', '# .github/workflows/ci.yml\nname: CI\non: [push, pull_request]\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v2\n    - name: Build\n      run: make\n    - name: Test\n      run: make test\n    - name: Coverage\n      run: make coverage\n    - name: Lint\n      run: make lint', 'CI runs tests automatically. Every push, pull request. Catch bugs early. GitHub Actions, Jenkins, GitLab CI. Essential for teams.', 13, 10),
(4, 23, 'Performance Metrics', 'class PerformanceMonitor {\n    std::chrono::high_resolution_clock::time_point start;\n    std::string name;\npublic:\n    PerformanceMonitor(const std::string& n) : name(n) {\n        start = std::chrono::high_resolution_clock::now();\n    }\n    ~PerformanceMonitor() {\n        auto end = std::chrono::high_resolution_clock::now();\n        auto duration = std::chrono::duration_cast<\n            std::chrono::microseconds>(end - start);\n        std::cout << name << ": " << duration.count() << "μs\\n";\n    }\n};\n// Usage: PerformanceMonitor pm("Function");', 'RAII performance monitoring. Automatic timing with destructor. Microsecond precision. No manual start/stop. Profile critical sections.', 3, 10),
(4, 24, 'A/B Testing', 'import hashlib\nimport random\n\ndef get_variant(user_id, test_name, variants=[''A'', ''B'']):\n    # Deterministic assignment\n    hash_input = f"{user_id}:{test_name}"\n    hash_value = hashlib.md5(hash_input.encode()).hexdigest()\n    index = int(hash_value[:8], 16) % len(variants)\n    return variants[index]\n\ndef track_metric(user_id, test_name, metric, value):\n    variant = get_variant(user_id, test_name)\n    # Log to analytics\n    analytics.track(user_id, metric, value, {''variant'': variant})', 'A/B testing compares variations. Deterministic user assignment. Track metrics per variant. Statistical significance required. Data-driven decisions.', 1, 10),
(4, 25, 'Regression Testing', '#!/bin/bash\n# Regression test suite\nTESTS_DIR="tests"\nEXPECTED_DIR="expected"\nOUTPUT_DIR="output"\n\nfor test in $TESTS_DIR/*.in; do\n    name=$(basename $test .in)\n    ./program < $test > $OUTPUT_DIR/$name.out\n    if diff -q $OUTPUT_DIR/$name.out $EXPECTED_DIR/$name.expected; then\n        echo "✓ $name passed"\n    else\n        echo "✗ $name failed"\n        diff $OUTPUT_DIR/$name.out $EXPECTED_DIR/$name.expected\n    fi\ndone', 'Regression tests prevent feature breaks. Compare output to expected. Automated verification. Run before each release. Confidence in changes.', 14, 10),
(4, 26, 'Mutation Testing', '# Original code\ndef is_positive(n):\n    return n > 0\n\n# Mutations:\n# 1. return n >= 0  (boundary)\n# 2. return n < 0   (operator)\n# 3. return True    (constant)\n\n# If tests still pass with mutations,\n# tests are inadequate\n\n# Tools: mutmut (Python), Stryker (JS), Pitest (Java)\n# Run: mutmut run --paths-to-mutate=src/', 'Mutation testing validates test quality. Changes code to verify tests catch it. Finds inadequate tests. Higher confidence than coverage.', 1, 10),
(4, 27, 'Smoke Testing', 'def smoke_test():\n    """Quick sanity check of critical features"""\n    \n    # Can we connect to database?\n    assert database.ping()\n    \n    # Can we reach external APIs?\n    assert requests.get(API_URL).status_code == 200\n    \n    # Can we render homepage?\n    response = client.get("/")\n    assert response.status_code == 200\n    assert "Welcome" in response.text\n    \n    # Basic functionality works?\n    assert calculate_price(100, 0.1) == 90\n    \n    print("✓ Smoke tests passed")', 'Smoke tests verify basic functionality. Quick sanity check. Run after deployment. Catch major breaks early. Not comprehensive.', 1, 10),
(4, 28, 'Test Doubles', '// Test double types:\n\n// Dummy - passed but not used\nvoid test_log(DummyLogger logger) { /* ... */ }\n\n// Stub - returns canned responses\nclass StubDatabase {\n    User getUser(int id) { return User("Test", 25); }\n};\n\n// Spy - records calls\nclass SpyEmailer {\n    vector<string> sent;\n    void send(string email) { sent.push_back(email); }\n};\n\n// Mock - verifies interactions\nclass MockPayment {\n    void charge(double amount) {\n        assert(amount == 99.99);\n    }\n};', 'Test doubles isolate units. Dummy: unused parameter. Stub: fixed responses. Spy: records calls. Mock: verifies behavior. Faster tests.', 3, 10),
(4, 29, 'Chaos Engineering', 'import random\nimport time\n\nclass ChaosMonkey:\n    def __init__(self, failure_rate=0.1):\n        self.failure_rate = failure_rate\n    \n    def maybe_fail(self):\n        if random.random() < self.failure_rate:\n            raise Exception("Chaos strike!")\n    \n    def add_latency(self, max_ms=1000):\n        delay = random.uniform(0, max_ms) / 1000\n        time.sleep(delay)\n    \n    def corrupt_data(self, data):\n        if random.random() < self.failure_rate:\n            # Flip random bit\n            byte_array = bytearray(data)\n            byte_array[random.randint(0, len(data)-1)] ^= 1\n            return bytes(byte_array)', 'Chaos engineering tests resilience. Inject failures randomly. Network delays, crashes, corruption. Find weaknesses before production. Netflix pioneered.', 1, 10),
(4, 30, 'End-to-End Testing', 'from selenium import webdriver\nfrom selenium.webdriver.common.by import By\n\ndef test_user_journey():\n    driver = webdriver.Chrome()\n    \n    # Navigate to site\n    driver.get("http://localhost:3000")\n    \n    # Login\n    driver.find_element(By.ID, "username").send_keys("user")\n    driver.find_element(By.ID, "password").send_keys("pass")\n    driver.find_element(By.ID, "login-btn").click()\n    \n    # Verify dashboard\n    assert "Dashboard" in driver.title\n    \n    # Complete purchase flow\n    driver.find_element(By.CLASS_NAME, "product").click()\n    driver.find_element(By.ID, "add-to-cart").click()\n    driver.find_element(By.ID, "checkout").click()', 'E2E tests complete user workflows. Real browser automation. Selenium, Cypress, Playwright. Slow but catch integration issues. Critical paths only.', 1, 10);